{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis (LSA) Overview\n",
    "\n",
    "Latent Semantic Analysis (LSA) is a foundational technique in natural language processing and information retrieval. It identifies patterns in the relationships between terms and documents and uncovers latent semantic structures, effectively grouping together terms that are used in similar contexts.\n",
    "\n",
    "### Steps in LSA:\n",
    "\n",
    "1. **Term-Document Matrix Creation**:\n",
    "   LSA constructs a matrix that represents the frequency of terms (words) across a set of documents. The matrix entries may be raw counts or, more commonly, weighted frequencies such as TF-IDF scores.\n",
    "\n",
    "2. **Matrix Decomposition**:\n",
    "   The term-document matrix is decomposed using Singular Value Decomposition (SVD). SVD separates the matrix into three components: a term-concept matrix, a diagonal matrix of singular values, and a concept-document matrix.\n",
    "\n",
    "3. **Dimensionality Reduction**:\n",
    "   By selecting the top `k` singular values and their corresponding vectors, LSA reduces the dimensionality of the term and document space to the `k` most informative concepts. This step helps in denoising the data and clarifying the structure.\n",
    "\n",
    "4. **Concept Identification**:\n",
    "   In the reduced `k`-dimensional space, terms and documents are now associated with latent concepts, which can often be interpreted as topics. The proximity of terms and documents within this space indicates their semantic similarity.\n",
    "\n",
    "5. **Similarity Measurement**:\n",
    "   LSA allows for the measurement of semantic similarity between terms and documents by using the cosine similarity of their vectors in the reduced space. Small angles between vectors indicate a high degree of semantic similarity.\n",
    "\n",
    "LSA is particularly adept at dealing with synonymy and polysemyâ€”common challenges in language processing. However, it does not account for word order or syntactic nuances, and the choice of `k` is crucial for the method's effectiveness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5a1LAka_8B4v"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import CoherenceModel\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "### Text Vectorization and LSA Application:\n",
    "\n",
    "- Vectorizes the cleaned text using TF-IDF with specified max and min document frequency thresholds, excluding common English stop words.\n",
    "- Apply LSA using TruncatedSVD to the TF-IDF matrix to identify latent topics within the data.\n",
    "# Loading the data\n",
    "data = pd.read_csv(\"train_no_simplify.csv\")\n",
    "\n",
    "# Extracting the cleaned text\n",
    "texts = data['clean_text'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization and LSA Application:\n",
    "\n",
    "- Vectorizes the cleaned text using TF-IDF with specified max and min document frequency thresholds, excluding common English stop words.\n",
    "- Apply LSA using TruncatedSVD to the TF-IDF matrix to identify latent topics within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "czaonStb9Mhp"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Define the number of topics\n",
    "n_topics = 20\n",
    "\n",
    "# Vectorize the cleaned text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_df=100, min_df=5, stop_words='english')\n",
    "dtm_tfidf = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Applying LSA (Truncated SVD) on the TF-IDF matrix\n",
    "lsa_model = TruncatedSVD(n_components=n_topics, n_iter=10)\n",
    "lsa_topic_matrix = lsa_model.fit_transform(dtm_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8yBnzgC39vM6"
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Ensure texts_list is a list of lists of tokens\n",
    "texts_list = [text.split() for text in texts]\n",
    "gensim_dictionary = Dictionary(texts_list)\n",
    "\n",
    "\n",
    "n_top_words = 10\n",
    "words = np.array(vectorizer.get_feature_names())\n",
    "top_words = [words[np.argsort(topic)[-n_top_words:]] for topic in lsa_model.components_]\n",
    "\n",
    "# Create the topics list expected by CoherenceModel\n",
    "topics = [list(topic) for topic in top_words]\n",
    "cm = CoherenceModel(topics=topics, texts=texts_list, dictionary=gensim_dictionary, coherence='c_v')\n",
    "coherence_score = cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DydQ6x8p9ouy",
    "outputId": "6338506d-38c4-4bb9-bd8c-a90db0362696"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5014920513250186"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsIydz4-_r8P",
    "outputId": "38c19efe-3f1c-4464-961a-96eba9c9dafe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755777164947796\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_topic_exclusivity(model, feature_names, top_n_words=20):\n",
    "    \"\"\"Calculates the topic exclusivity score for a given topic model.\n",
    "\n",
    "    Args:\n",
    "        model: The fitted topic model with a `components_` attribute containing topic-word distributions.\n",
    "        feature_names: A list of feature names corresponding to the columns of the topic-word matrix.\n",
    "        top_n_words: The number of top words to consider for exclusivity calculation (default: 20).\n",
    "\n",
    "    Returns:\n",
    "        The overall topic exclusivity score, averaged across all topics.\n",
    "    \"\"\"\n",
    "\n",
    "    topics = model.components_\n",
    "    exclusivity_scores = []\n",
    "\n",
    "    for topic_idx, topic in enumerate(topics):\n",
    "        top_features_ind = topic.argsort()[:-top_n_words-1:-1]\n",
    "        top_features_ind = top_features_ind.astype(int)  # Ensure it's an integer array\n",
    "        top_features = [feature_names[i] for i in top_features_ind]  # Use list comprehension for indexing\n",
    "\n",
    "\n",
    "        other_topics = np.delete(topics, topic_idx, axis=0)\n",
    "\n",
    "        # Check for zero denominator and handle it appropriately\n",
    "        if np.sum(other_topics[:, top_features_ind]) == 0:\n",
    "            topic_exclusivity_score = np.inf  # Assign infinite exclusivity if no overlap\n",
    "        else:\n",
    "            topic_exclusivity_score = np.sum(topic[top_features_ind]) / np.sum(other_topics[:, top_features_ind])\n",
    "\n",
    "        exclusivity_scores.append(topic_exclusivity_score)\n",
    "\n",
    "    # Use a robust averaging method to handle potential outliers\n",
    "    overall_exclusivity = np.median(exclusivity_scores)  # Consider np.mean as well\n",
    "\n",
    "    return overall_exclusivity\n",
    "\n",
    "# Calculating Topic Exclusivity\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "topic_exclusivity_score = calculate_topic_exclusivity(lsa_model, feature_names)\n",
    "print(topic_exclusivity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnYEmceBEma-",
    "outputId": "cab89366-d648-4d7e-e55c-c9046174c52a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl_divergence: 1.549283\n"
     ]
    }
   ],
   "source": [
    "# Adjusting the number of topics to be less than the number of features\n",
    "n_topics_adjusted = min(dtm_tfidf.shape[1] - 1, 5)  # Setting a maximum of 5 topics for this small dataset\n",
    "\n",
    "# Re-applying LSA (Truncated SVD) with the adjusted number of topics\n",
    "lsa_model_adjusted = TruncatedSVD(n_components=n_topics_adjusted, n_iter=10)\n",
    "lsa_topic_matrix_adjusted = lsa_model_adjusted.fit_transform(dtm_tfidf)\n",
    "\n",
    "# Recalculating the KL Divergence and Topic Diversity score with the adjusted number of topics\n",
    "topic_diversity_scores_adjusted = []\n",
    "for i in range(n_topics_adjusted):\n",
    "    divergences = []\n",
    "    for j in range(n_topics_adjusted):\n",
    "        if i != j:\n",
    "            divergences.append(kl_divergence(lsa_topic_matrix_adjusted[:, i], lsa_topic_matrix_adjusted[:, j]))\n",
    "    topic_diversity_scores_adjusted.append(np.mean(divergences))\n",
    "\n",
    "# Calculate the overall Topic Diversity score as the mean of individual topic scores\n",
    "topic_diversity_score_adjusted = np.mean(topic_diversity_scores_adjusted)\n",
    "topic_diversity_score_adjusted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2UQKalBHe7t"
   },
   "source": [
    "1. **Coherence Score (0.501)**:\n",
    "   - The coherence score measures how semantically related the top words within each topic are. A score of 0.501 indicates that the topics have a moderate level of coherence. This means that while the top words in each topic exhibit some meaningful connections, there is room for improvement to enhance the overall coherence and interpretability of the topics.\n",
    "\n",
    "2. **Topic Exclusivity Score (0.756)**:\n",
    "   - The topic exclusivity score evaluates the distinctiveness of words within each topic. A score of 0.756 suggests that the topics are relatively exclusive, meaning that the words in each topic are distinct and not highly shared with words from other topics. This is a positive sign, as it indicates that the model has succeeded in creating internally coherent and separate topics.\n",
    "\n",
    "3. **KL Divergence (1.549)**:\n",
    "   - KL Divergence, in the context of topic modeling, measures the dissimilarity between topics. A value of 1.549 suggests that the topics exhibit a moderate level of diversity. While they are not highly dissimilar, they also do not overlap significantly. This balance between diversity and relatedness between topics can be useful depending on the application.\n",
    "\n",
    "In summary, the scores collectively indicate that the topic modeling algorithm has generated topics with moderate coherence, high exclusivity, and moderate diversity. While the topics are distinct and not highly overlapping, there is potential for enhancing the interpretability of topics by improving coherence. Depending on the specific goals of the topic modeling application, further refinement of the model's parameters or post-processing techniques may be considered to achieve the desired balance between coherence, exclusivity, and diversity in the generated topics."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
