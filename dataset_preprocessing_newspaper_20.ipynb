{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxrKTCd5FQjk",
        "outputId": "7e66889d-2c99-4752-c0b3-075422f24d33"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSZv3V16FTLG",
        "outputId": "5aad0c1d-b711-4ceb-e893-4ecdd3982c22"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_sQCulBKm0N",
        "outputId": "35126ba8-8278-442a-cc38-8da4d30fdca2"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install email-validator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E40bY84yNT8G",
        "outputId": "3a23bea7-81b5-43dc-fbdf-0c66a24f7736"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: email-validator in /usr/local/lib/python3.10/dist-packages (2.1.0.post1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator) (2.4.2)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator) (3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRyWd_EQK3ZW",
        "outputId": "a3540901-52df-4ee7-d5b3-f757a5ee4b70"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gic9xbeHJtj",
        "outputId": "cfc2eb8f-c7dc-42d5-cc89-e583d15c2fd7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import spacy\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import contractions\n",
        "import inflect\n",
        "\n",
        "newsgroup_data = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
        "documents = newsgroup_data.data\n",
        "categories = newsgroup_data.target\n",
        "\n",
        "df = pd.DataFrame({'text': documents, 'category': categories})"
      ],
      "metadata": {
        "id": "V5YcghVKDF-c"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmv_emails_websites(string):\n",
        "    new_str = re.sub(r\"\\S+@\\S+\", '', string)\n",
        "    new_str = re.sub(r\"\\S+.co\\S+\", '', new_str)\n",
        "    new_str = re.sub(r\"\\S+.ed\\S+\", '', new_str)\n",
        "    new_str = re.sub(r\"[0-9]+\", '', new_str)\n",
        "    return new_str\n",
        "\n",
        "def sentence_simplifier(sentence):\n",
        "  stemmer = PorterStemmer()\n",
        "  simplified_words = [stemmer.stem(word) for word in sentence.split()]\n",
        "  return \" \".join(simplified_words)\n",
        "\n",
        "def preprocess_text(input_text):\n",
        "    # remove emails\n",
        "    clean_text = rmv_emails_websites(input_text)\n",
        "    # simplify sentences writing -> write\n",
        "    clean_text = sentence_simplifier(clean_text)\n",
        "    # all within square brackets\n",
        "    clean_text = re.sub(r'\\[.*?\\]', '', clean_text)\n",
        "    # all within round brackets\n",
        "    clean_text = re.sub(r'\\(.*?\\)', '', clean_text)\n",
        "    # URLs and Links\n",
        "    clean_text = re.sub(r'http\\S+', '', clean_text)\n",
        "    # Lowercase\n",
        "    clean_text = clean_text.lower()\n",
        "    # white space\n",
        "    clean_text = re.sub('\\s+', ' ', clean_text)\n",
        "    # Expand contractions: can't -> cannot\n",
        "    clean_text = contractions.fix(clean_text)\n",
        "    # Remove special characters\n",
        "    clean_text = re.sub('[^a-zA-Z0-9\\s]', '', clean_text)\n",
        "    # Numbers to text\n",
        "    temp = inflect.engine()\n",
        "    words = []\n",
        "    for word in clean_text.split():\n",
        "        if word.isdigit():\n",
        "            words.append(temp.number_to_words(word))\n",
        "        else:\n",
        "            words.append(word)\n",
        "    clean_text = ' '.join(words)\n",
        "\n",
        "    tokens = word_tokenize(clean_text)\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    clean_text = ' '.join(tokens)\n",
        "    # Punctuation\n",
        "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
        "\n",
        "    return clean_text\n"
      ],
      "metadata": {
        "id": "XqDYRN75HGnM"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_text = df['text'][0]\n",
        "print(dummy_text)\n",
        "print('-'*30)\n",
        "dummy_text = preprocess_text(dummy_text)\n",
        "print(dummy_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsjQXg9gHR0f",
        "outputId": "f977f404-1465-467c-e5d3-50932aa9a708"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\n",
            "Subject: Need info on 88-89 Bonneville\n",
            "Organization: University at Buffalo\n",
            "Lines: 10\n",
            "News-Software: VAX/VMS VNEWS 1.41\n",
            "Nntp-Posting-Host: ubvmsd.cc.buffalo.edu\n",
            "\n",
            "\n",
            " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
            "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
            "differences are far as features or performance. I am also curious to\n",
            "know what the book value is for prefereably the 89 model. And how much\n",
            "less than book value can you usually get them for. In other words how\n",
            "much are they in demand this time of year. I have heard that the mid-spring\n",
            "early summer is the best time to buy.\n",
            "\n",
            "\t\t\tNeil Gandler\n",
            "\n",
            "------------------------------\n",
            "subject need info bonnevil organization univers buffalo lines newssoftware vaxvm vnew nntppostinghost model bonnevilles heard le se lse sse ssei could someon tell differ far featur performance also curiou know book valu prefer model much less book valu usual get word much demand thi time year heard midspr earli summer best time buy neil gandler\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Takes approximately 1 minute to preprocess all the text data"
      ],
      "metadata": {
        "id": "4-yWw9J0lLWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "7ZVK-CxXFIAH"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSnAvWrel-sz",
        "outputId": "399c375a-5a40-4536-c104-ded337379983"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7532"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('test.csv', index=False)"
      ],
      "metadata": {
        "id": "eLQWWxchlR-Y"
      },
      "execution_count": 91,
      "outputs": []
    }
  ]
}