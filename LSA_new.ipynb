{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a1LAka_8B4v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from gensim.models import CoherenceModel\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# Loading the data\n",
        "data = pd.read_csv(\"/content/train_no_simplify.csv\")\n",
        "\n",
        "# Extracting the cleaned text\n",
        "texts = data['clean_text'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Define the number of topics\n",
        "n_topics = 20\n",
        "\n",
        "# Vectorize the cleaned text using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_df=100, min_df=5, stop_words='english')\n",
        "dtm_tfidf = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Applying LSA (Truncated SVD) on the TF-IDF matrix\n",
        "lsa_model = TruncatedSVD(n_components=n_topics, n_iter=10)\n",
        "lsa_topic_matrix = lsa_model.fit_transform(dtm_tfidf)\n"
      ],
      "metadata": {
        "id": "czaonStb9Mhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Ensure texts_list is a list of lists of tokens\n",
        "texts_list = [text.split() for text in texts]\n",
        "gensim_dictionary = Dictionary(texts_list)\n",
        "\n",
        "\n",
        "n_top_words = 10\n",
        "words = np.array(vectorizer.get_feature_names_out())\n",
        "top_words = [words[np.argsort(topic)[-n_top_words:]] for topic in lsa_model.components_]\n",
        "\n",
        "# Create the topics list expected by CoherenceModel\n",
        "topics = [list(topic) for topic in top_words]\n",
        "cm = CoherenceModel(topics=topics, texts=texts_list, dictionary=gensim_dictionary, coherence='c_v')\n",
        "coherence_score = cm.get_coherence()"
      ],
      "metadata": {
        "id": "8yBnzgC39vM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DydQ6x8p9ouy",
        "outputId": "6338506d-38c4-4bb9-bd8c-a90db0362696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4757086283363246"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_topic_exclusivity(model, feature_names, top_n_words=20):\n",
        "    \"\"\"Calculates the topic exclusivity score for a given topic model.\n",
        "\n",
        "    Args:\n",
        "        model: The fitted topic model with a `components_` attribute containing topic-word distributions.\n",
        "        feature_names: A list of feature names corresponding to the columns of the topic-word matrix.\n",
        "        top_n_words: The number of top words to consider for exclusivity calculation (default: 20).\n",
        "\n",
        "    Returns:\n",
        "        The overall topic exclusivity score, averaged across all topics.\n",
        "    \"\"\"\n",
        "\n",
        "    topics = model.components_\n",
        "    exclusivity_scores = []\n",
        "\n",
        "    for topic_idx, topic in enumerate(topics):\n",
        "        top_features_ind = topic.argsort()[:-top_n_words-1:-1]\n",
        "        top_features = feature_names[top_features_ind]\n",
        "\n",
        "        other_topics = np.delete(topics, topic_idx, axis=0)\n",
        "\n",
        "        # Check for zero denominator and handle it appropriately\n",
        "        if np.sum(other_topics[:, top_features_ind]) == 0:\n",
        "            topic_exclusivity_score = np.inf  # Assign infinite exclusivity if no overlap\n",
        "        else:\n",
        "            topic_exclusivity_score = np.sum(topic[top_features_ind]) / np.sum(other_topics[:, top_features_ind])\n",
        "\n",
        "        exclusivity_scores.append(topic_exclusivity_score)\n",
        "\n",
        "    # Use a robust averaging method to handle potential outliers\n",
        "    overall_exclusivity = np.median(exclusivity_scores)  # Consider np.mean as well\n",
        "\n",
        "    return overall_exclusivity\n",
        "\n",
        "# Calculating Topic Exclusivity\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "topic_exclusivity_score = calculate_topic_exclusivity(lsa_model, feature_names)\n",
        "print(topic_exclusivity_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsIydz4-_r8P",
        "outputId": "38c19efe-3f1c-4464-961a-96eba9c9dafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6288398456379947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import rel_entr\n",
        "\n",
        "def calculate_average_topic_divergence(model):\n",
        "    topics = model.components_  # Access topic-word distributions\n",
        "    divergence_matrix = np.zeros((len(topics), len(topics)))\n",
        "\n",
        "    for i in range(len(topics)):\n",
        "        for j in range(i + 1, len(topics)):\n",
        "            divergence = rel_entr(topics[i], topics[j])\n",
        "\n",
        "            # Handle zero denominator and potential numerical issues:\n",
        "            if np.isinf(divergence).any():  # Check for infinity\n",
        "                divergence_matrix[i, j] = np.inf  # Assign infinity\n",
        "            else:\n",
        "                divergence_matrix[i, j] = divergence\n",
        "\n",
        "            divergence_matrix[j, i] = divergence_matrix[i, j]\n",
        "\n",
        "    # Calculate average divergence, ignoring infinity values:\n",
        "    average_divergence = np.nanmean(divergence_matrix[~np.eye(divergence_matrix.shape[0], dtype=bool)])\n",
        "\n",
        "    return average_divergence\n",
        "\n",
        "\n",
        "\n",
        "average_divergence = calculate_average_topic_divergence(lsa_model)  # Adjust the model argument as needed\n",
        "print(\"Average Topic Divergence:\", average_divergence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnYEmceBEma-",
        "outputId": "cab89366-d648-4d7e-e55c-c9046174c52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Topic Divergence: inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t2UQKalBHe7t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}